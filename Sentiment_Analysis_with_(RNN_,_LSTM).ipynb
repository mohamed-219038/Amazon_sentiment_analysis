{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 → RNN"
      ],
      "metadata": {
        "id": "AeNB0c1sSvE_"
      },
      "id": "AeNB0c1sSvE_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Sentiment Analysis with RNN on Amazon Fine Food Reviews\n",
        "\n",
        "## Dataset\n",
        "- **Amazon Fine Food Reviews**  \n",
        "- [Download from Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)  \n",
        "- Dataset contains **500,000+ reviews** with ratings (1–5 stars).\n",
        "\n",
        "## Objective\n",
        "- Build a **Recurrent Neural Network (RNN)** model to predict review sentiment:\n",
        "  - **Multi-class** → Ratings from 1 to 5 stars  \n",
        "\n",
        "\n",
        "## Steps\n",
        "\n",
        "### 1. Data Preprocessing\n",
        "- Load the CSV file → focus on **`Text`** + **`Score`** columns.\n",
        "- Clean text: lowercase, remove punctuation, (optional: remove stopwords).\n",
        "- Tokenize reviews (convert words to numbers).\n",
        "- Pad sequences to a fixed length.\n",
        "- Convert labels:\n",
        "  - Multi-class (1–5 → one-hot encoded).\n",
        "\n",
        "### 2. Build RNN Model\n",
        "- Use **Embedding Layer** to convert tokens into vectors.\n",
        "- Add **SimpleRNN layer** (e.g., 32 or 64 units).\n",
        "- Add **Dense output layer**:\n",
        "  - Activation = `softmax` (for multi-class classification).\n",
        "\n",
        "### 3. Training\n",
        "- Compile with:\n",
        "  - Optimizer → `adam`\n",
        "  - Loss → `categorical_crossentropy` (multi-class)\n",
        "  - Metric → `accuracy`\n",
        "- Train for **5–10 epochs**.\n",
        "- Use a **validation split** (e.g., 20%).\n",
        "\n",
        "### 4. Evaluation\n",
        "- Evaluate model on test set.\n",
        "- Show:\n",
        "  - **Accuracy score**\n",
        "  - **Confusion matrix**\n",
        "- Print a few **example predictions**:\n",
        "  - Input review\n",
        "  - True label\n",
        "  - Predicted sentiment\n",
        "\n",
        "### 5. User Input Prediction\n",
        "- After training, let the user type **any review sentence**.  \n",
        "- Preprocess it the same way (tokenize + pad).  \n",
        "- Pass it to the trained RNN model.  \n",
        "- Print the predicted sentiment (Rating 1–5).  \n",
        "\n",
        "## Hints\n",
        "- Start with a **small subset** of the dataset (e.g., 20k reviews) to save training time.\n",
        "- Watch for **overfitting** (training accuracy much higher than validation)."
      ],
      "metadata": {
        "id": "8xifqb8mSMaq"
      },
      "id": "8xifqb8mSMaq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install kagglehub (only once per Colab session)\n",
        "!pip install -q kagglehub[pandas-datasets]\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Path to the dataset file inside the Kaggle dataset\n",
        "file_path = \"Reviews.csv\"   # <- important, dataset contains this CSV file\n",
        "\n",
        "# Load dataset directly as a pandas DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"snap/amazon-fine-food-reviews\",  # dataset slug\n",
        "    file_path\n",
        ")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "_whYeO36iMvp",
        "outputId": "93e4c69a-36e2-4790-f1d7-c677945e84e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_whYeO36iMvp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-87149450.py:11: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'amazon-fine-food-reviews' dataset.\n",
            "Shape: (568454, 10)\n",
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "subset, _ = train_test_split(\n",
        "    df[[\"Text\", \"Score\"]],\n",
        "    train_size=40000,\n",
        "    stratify=df[\"Score\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train/test split (80/20) again\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    subset[\"Text\"],\n",
        "    subset[\"Score\"],\n",
        "    test_size=0.2,\n",
        "    stratify=subset[\"Score\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Shuffle\n",
        "train_texts, train_labels = shuffle(train_texts, train_labels, random_state=42)\n",
        "test_texts, test_labels = shuffle(test_texts, test_labels, random_state=42)\n"
      ],
      "metadata": {
        "id": "DW6UWjMRiMto"
      },
      "id": "DW6UWjMRiMto",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts"
      ],
      "metadata": {
        "id": "gD3l8foep_Uz",
        "outputId": "71ca9f42-2f0f-4b21-c400-6b7a099103a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "id": "gD3l8foep_Uz",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305132    I usually find these at my local health food s...\n",
              "114315    Eagle Pack has turned my picky eater into an e...\n",
              "374696    C&P Organix is a great line of dog food.  I'm ...\n",
              "238117    This is the sugar I have come to use for every...\n",
              "324513    I originally gave 5 star rating, but none of t...\n",
              "                                ...                        \n",
              "402115    These are so good.  My kids have eaten them si...\n",
              "73069     The taste reminds me of when you accidentally ...\n",
              "134409    Our Pom hates taking pills - hide it in someth...\n",
              "458767    The directions on the bottle state that one sh...\n",
              "204017    Canidae is an excellent food that is meat base...\n",
              "Name: Text, Length: 32000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>305132</th>\n",
              "      <td>I usually find these at my local health food s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114315</th>\n",
              "      <td>Eagle Pack has turned my picky eater into an e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374696</th>\n",
              "      <td>C&amp;P Organix is a great line of dog food.  I'm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238117</th>\n",
              "      <td>This is the sugar I have come to use for every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324513</th>\n",
              "      <td>I originally gave 5 star rating, but none of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402115</th>\n",
              "      <td>These are so good.  My kids have eaten them si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73069</th>\n",
              "      <td>The taste reminds me of when you accidentally ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134409</th>\n",
              "      <td>Our Pom hates taking pills - hide it in someth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458767</th>\n",
              "      <td>The directions on the bottle state that one sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204017</th>\n",
              "      <td>Canidae is an excellent food that is meat base...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(sen):\n",
        "    sen=str(sen).lower()\n",
        "    sen=re.sub('[^\\w\\s]','',sen)\n",
        "    sen=re.sub('\\d','',sen)\n",
        "    return sen\n",
        "\n",
        "train_texts=train_texts.apply(clean_text)\n",
        "test_texts=test_texts.apply(clean_text)"
      ],
      "metadata": {
        "id": "9IgDwUw-iMpd",
        "outputId": "53c63c6d-071c-41e3-c0d9-6e374dda12e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9IgDwUw-iMpd",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:4: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
            "<>:4: SyntaxWarning: invalid escape sequence '\\w'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
            "/tmp/ipython-input-3822074521.py:4: SyntaxWarning: invalid escape sequence '\\w'\n",
            "  sen=re.sub('[^\\w\\s]','',sen)\n",
            "/tmp/ipython-input-3822074521.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  sen=re.sub('\\d','',sen)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    return re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "train_texts=train_texts.apply(remove_punctuation)\n",
        "test_texts=test_texts.apply(remove_punctuation)\n"
      ],
      "metadata": {
        "id": "tOcjkcQxiMlh"
      },
      "id": "tOcjkcQxiMlh",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts"
      ],
      "metadata": {
        "id": "puIs-GE1phRx",
        "outputId": "9f370fbb-d689-41ee-cc05-1818b0869c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "id": "puIs-GE1phRx",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305132    i usually find these at my local health food s...\n",
              "114315    eagle pack has turned my picky eater into an e...\n",
              "374696    cp organix is a great line of dog food  im not...\n",
              "238117    this is the sugar i have come to use for every...\n",
              "324513    i originally gave  star rating but none of the...\n",
              "                                ...                        \n",
              "402115    these are so good  my kids have eaten them sin...\n",
              "73069     the taste reminds me of when you accidentally ...\n",
              "134409    our pom hates taking pills  hide it in somethi...\n",
              "458767    the directions on the bottle state that one sh...\n",
              "204017    canidae is an excellent food that is meat base...\n",
              "Name: Text, Length: 32000, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>305132</th>\n",
              "      <td>i usually find these at my local health food s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114315</th>\n",
              "      <td>eagle pack has turned my picky eater into an e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374696</th>\n",
              "      <td>cp organix is a great line of dog food  im not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238117</th>\n",
              "      <td>this is the sugar i have come to use for every...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324513</th>\n",
              "      <td>i originally gave  star rating but none of the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402115</th>\n",
              "      <td>these are so good  my kids have eaten them sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73069</th>\n",
              "      <td>the taste reminds me of when you accidentally ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134409</th>\n",
              "      <td>our pom hates taking pills  hide it in somethi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458767</th>\n",
              "      <td>the directions on the bottle state that one sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204017</th>\n",
              "      <td>canidae is an excellent food that is meat base...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def stop(text):\n",
        "  words = text.split()\n",
        "  words = [w for w in words if w not in stop_words]  # optional\n",
        "  return \" \".join(words)\n",
        "\n",
        "train_texts = [stop(t) for t in train_texts]\n",
        "test_texts = [stop(t) for t in test_texts]"
      ],
      "metadata": {
        "id": "EU-obOjbuLlN",
        "outputId": "621b271b-47ed-40a2-fcd5-53da4f89d7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EU-obOjbuLlN",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "X_test = tokenizer.texts_to_sequences(test_texts)\n",
        "word_index=tokenizer.word_index\n",
        "X_train = tokenizer.texts_to_sequences(train_texts)\n",
        "padded_sequences_train = pad_sequences(X_train)\n",
        "padded_sequences_test = pad_sequences(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nPAqOYHEiMjX"
      },
      "id": "nPAqOYHEiMjX",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels = train_labels - 1\n",
        "test_labels = test_labels - 1\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes=5)\n",
        "test_labels = to_categorical(test_labels, num_classes=5)"
      ],
      "metadata": {
        "id": "iSmndqQtohhQ"
      },
      "id": "iSmndqQtohhQ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense,Dropout\n",
        "rnn_model=Sequential([Embedding(input_dim=len(word_index)+1,output_dim=64,input_length=padded_sequences_train.shape[1]),\n",
        "                      SimpleRNN(64),\n",
        "                      Dropout(0.5),\n",
        "                      Dense(5,activation=\"softmax\")])\n",
        "rnn_model.compile(optimizer=\"adam\",loss=\"crossentropy\",metrics=[\"accuracy\"])\n",
        "rnn_model.fit(\n",
        "    padded_sequences_train, train_labels,\n",
        "    validation_data=(padded_sequences_test, test_labels),\n",
        "    batch_size=64,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "Ce7FTemmohfR",
        "outputId": "dd9116a1-5160-4dd5-f92d-2b72b97ca835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ce7FTemmohfR",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 418ms/step - accuracy: 0.6281 - loss: 1.1177 - val_accuracy: 0.6840 - val_loss: 0.8795\n",
            "Epoch 2/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 377ms/step - accuracy: 0.7305 - loss: 0.7371 - val_accuracy: 0.6944 - val_loss: 0.9059\n",
            "Epoch 3/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 384ms/step - accuracy: 0.8662 - loss: 0.4118 - val_accuracy: 0.6511 - val_loss: 1.0236\n",
            "Epoch 4/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 380ms/step - accuracy: 0.9495 - loss: 0.1775 - val_accuracy: 0.6420 - val_loss: 1.2631\n",
            "Epoch 5/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 383ms/step - accuracy: 0.9787 - loss: 0.0781 - val_accuracy: 0.6447 - val_loss: 1.4783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6a9cd3edb0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred_probs = rnn_model.predict(padded_sequences_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)   # predicted class (0–4)\n",
        "y_true = np.argmax(test_labels, axis=1)"
      ],
      "metadata": {
        "id": "f4VZ78BHohdV",
        "outputId": "9fe4f16e-ff5d-4e24-ef01-f6e88b628963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f4VZ78BHohdV",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(60):\n",
        "    print(f\"Review {i+1}: True={y_true[i]}, Pred={y_pred[i]}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lWgL7p_Kohbg",
        "outputId": "fff990e7-11c7-4808-9a4e-0ee6dadfdca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lWgL7p_Kohbg",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1: True=4, Pred=4\n",
            "Review 2: True=4, Pred=4\n",
            "Review 3: True=4, Pred=4\n",
            "Review 4: True=4, Pred=4\n",
            "Review 5: True=4, Pred=4\n",
            "Review 6: True=4, Pred=4\n",
            "Review 7: True=4, Pred=4\n",
            "Review 8: True=4, Pred=4\n",
            "Review 9: True=2, Pred=0\n",
            "Review 10: True=4, Pred=4\n",
            "Review 11: True=4, Pred=4\n",
            "Review 12: True=4, Pred=3\n",
            "Review 13: True=0, Pred=0\n",
            "Review 14: True=1, Pred=2\n",
            "Review 15: True=4, Pred=3\n",
            "Review 16: True=3, Pred=4\n",
            "Review 17: True=0, Pred=0\n",
            "Review 18: True=4, Pred=4\n",
            "Review 19: True=4, Pred=3\n",
            "Review 20: True=1, Pred=1\n",
            "Review 21: True=4, Pred=4\n",
            "Review 22: True=4, Pred=4\n",
            "Review 23: True=4, Pred=4\n",
            "Review 24: True=3, Pred=4\n",
            "Review 25: True=4, Pred=4\n",
            "Review 26: True=4, Pred=4\n",
            "Review 27: True=4, Pred=4\n",
            "Review 28: True=4, Pred=4\n",
            "Review 29: True=4, Pred=4\n",
            "Review 30: True=4, Pred=4\n",
            "Review 31: True=0, Pred=0\n",
            "Review 32: True=4, Pred=4\n",
            "Review 33: True=4, Pred=4\n",
            "Review 34: True=4, Pred=4\n",
            "Review 35: True=3, Pred=4\n",
            "Review 36: True=4, Pred=4\n",
            "Review 37: True=4, Pred=4\n",
            "Review 38: True=4, Pred=4\n",
            "Review 39: True=4, Pred=4\n",
            "Review 40: True=4, Pred=4\n",
            "Review 41: True=4, Pred=0\n",
            "Review 42: True=4, Pred=3\n",
            "Review 43: True=3, Pred=4\n",
            "Review 44: True=4, Pred=3\n",
            "Review 45: True=4, Pred=4\n",
            "Review 46: True=4, Pred=4\n",
            "Review 47: True=3, Pred=0\n",
            "Review 48: True=4, Pred=4\n",
            "Review 49: True=4, Pred=4\n",
            "Review 50: True=1, Pred=1\n",
            "Review 51: True=1, Pred=0\n",
            "Review 52: True=4, Pred=4\n",
            "Review 53: True=2, Pred=4\n",
            "Review 54: True=4, Pred=4\n",
            "Review 55: True=3, Pred=3\n",
            "Review 56: True=4, Pred=4\n",
            "Review 57: True=1, Pred=4\n",
            "Review 58: True=4, Pred=4\n",
            "Review 59: True=0, Pred=0\n",
            "Review 60: True=3, Pred=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "def print_score(model, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        # Convert labels (one-hot → integers)\n",
        "        y_true = np.argmax(y_train, axis=1)\n",
        "        # Predictions (probabilities → integers)\n",
        "        y_pred = np.argmax(model.predict(X_train), axis=1)\n",
        "\n",
        "        clf_report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True))\n",
        "        print(\"Train Result:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n{confusion_matrix(y_true, y_pred)}\\n\")\n",
        "\n",
        "    else:\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "        y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "        clf_report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True))\n",
        "        print(\"Test Result:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n{confusion_matrix(y_true, y_pred)}\\n\")\n"
      ],
      "metadata": {
        "id": "VTkKrTT9AYfr"
      },
      "id": "VTkKrTT9AYfr",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(rnn_model, padded_sequences_train, train_labels, padded_sequences_test, test_labels, train=True)\n"
      ],
      "metadata": {
        "id": "veJu-bX6ohTU",
        "outputId": "06d3ba97-f626-4921-b0db-646e1ae477fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "veJu-bX6ohTU",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 56ms/step\n",
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 99.53%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                     0            1            2            3             4  \\\n",
            "precision     0.992545     0.996379     0.992899     0.987947      0.997553   \n",
            "recall        0.995581     0.985084     0.990417     0.992952      0.997212   \n",
            "f1-score      0.994061     0.990699     0.991656     0.990443      0.997382   \n",
            "support    2942.000000  1676.000000  2400.000000  4540.000000  20442.000000   \n",
            "\n",
            "           accuracy     macro avg  weighted avg  \n",
            "precision  0.995313      0.993465      0.995319  \n",
            "recall     0.995313      0.992249      0.995313  \n",
            "f1-score   0.995313      0.992848      0.995313  \n",
            "support    0.995313  32000.000000  32000.000000  \n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            "[[ 2929     1     3     2     7]\n",
            " [    5  1651     5     8     7]\n",
            " [    3     2  2377     5    13]\n",
            " [    4     2     3  4508    23]\n",
            " [   10     1     6    40 20385]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(rnn_model, padded_sequences_train, train_labels, padded_sequences_test, test_labels, train=False)"
      ],
      "metadata": {
        "id": "luto4bi0BJui",
        "outputId": "a6209cc7-3efd-4fab-c42e-9ef202fe72fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "luto4bi0BJui",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 64.48%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                    0           1           2            3            4  \\\n",
            "precision    0.481752    0.273529    0.292105     0.304233     0.791322   \n",
            "recall       0.538043    0.221957    0.185000     0.303965     0.824462   \n",
            "f1-score     0.508344    0.245059    0.226531     0.304099     0.807552   \n",
            "support    736.000000  419.000000  600.000000  1135.000000  5110.000000   \n",
            "\n",
            "           accuracy    macro avg  weighted avg  \n",
            "precision   0.64475     0.428588      0.629175  \n",
            "recall      0.64475     0.414685      0.644750  \n",
            "f1-score    0.64475     0.418317      0.635560  \n",
            "support     0.64475  8000.000000   8000.000000  \n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            "[[ 396   73   54   55  158]\n",
            " [ 131   93   42   44  109]\n",
            " [  92   64  111  102  231]\n",
            " [  60   49   68  345  613]\n",
            " [ 143   61  105  588 4213]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "new_sentence=['this product is bad and horrible i hate it','Good Quality and very Delight and Great product']\n",
        "new_sentence=pd.Series(new_sentence)\n",
        "new_sentence=new_sentence.apply(clean_text)\n",
        "new_sentence=new_sentence.apply(remove_punctuation)\n",
        "new_sentence=[stop(t) for t in new_sentence]\n",
        "new_sequences=tokenizer.texts_to_sequences(new_sentence)\n",
        "new_padded_sequences=pad_sequences(new_sequences,maxlen=padded_sequences_train.shape[1])\n",
        "predictions=rnn_model.predict(new_padded_sequences)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "print(predicted_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "zNXsAFbuohRY",
        "outputId": "8479e110-508d-4978-fe87-af99b9dc3cf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zNXsAFbuohRY",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575ms/step\n",
            "[0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 – LSTM\n",
        "1. **Build LSTM Model**\n",
        "   - Keep preprocessing exactly the same.\n",
        "   - Replace `SimpleRNN` with `LSTM` (e.g., 64–128 units).\n",
        "   - Dense output (sigmoid or softmax).\n",
        "\n",
        "2. **Training**\n",
        "   - Same setup (adam, crossentropy, accuracy).\n",
        "   - Train for 5–10 epochs.\n",
        "\n",
        "3. **Evaluation**\n",
        "   - Compare accuracy with RNN model.\n",
        "   - Show confusion matrix.\n",
        "   - Example predictions.\n",
        "\n",
        "4. **User Input Prediction. **\n",
        "   - Take a sentence from user.\n",
        "   - Preprocess (tokenize + pad).\n",
        "   - Predict sentiment using the LSTM model.\n",
        "\n",
        "## Hints\n",
        "- Use a **smaller subset** (e.g., 20k reviews) for quick experiments.\n",
        "- Compare:\n",
        "  - Training speed (RNN faster, LSTM slower).\n",
        "  - Accuracy on long reviews.\n",
        "\n",
        "## Deliverables\n",
        "1. Notebook with:\n",
        "   - RNN implementation\n",
        "   - LSTM implementation\n",
        "2. Final accuracy + confusion matrix for both models.\n",
        "3. Comparison table (RNN vs LSTM).\n",
        "4. Demo that accepts **any user sentence** and predicts sentiment with both models."
      ],
      "metadata": {
        "id": "CETy2K0QS4TV"
      },
      "id": "CETy2K0QS4TV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "LSTM_model = Sequential([\n",
        "    Embedding(input_dim=len(word_index)+1,output_dim=64,input_length=padded_sequences_train.shape[1]),\n",
        "    LSTM(128),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "LSTM_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "6UyS8C97S7H0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "048c1f0d-7f7e-44b5-ead5-3a272499b52b"
      },
      "id": "6UyS8C97S7H0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model.fit(\n",
        "    padded_sequences_train, train_labels,\n",
        "    validation_data=(padded_sequences_test, test_labels),\n",
        "    batch_size=64,\n",
        "    epochs=5\n",
        ")"
      ],
      "metadata": {
        "id": "xOHKjaE4S6PB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f63eafb-7dd5-4c8e-a9f2-081105348fe0"
      },
      "id": "xOHKjaE4S6PB",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1014s\u001b[0m 2s/step - accuracy: 0.6430 - loss: 1.0711 - val_accuracy: 0.6984 - val_loss: 0.8244\n",
            "Epoch 2/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1049s\u001b[0m 2s/step - accuracy: 0.7336 - loss: 0.7138 - val_accuracy: 0.7094 - val_loss: 0.8118\n",
            "Epoch 3/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m943s\u001b[0m 2s/step - accuracy: 0.7855 - loss: 0.5759 - val_accuracy: 0.7050 - val_loss: 0.8361\n",
            "Epoch 4/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1003s\u001b[0m 2s/step - accuracy: 0.8402 - loss: 0.4399 - val_accuracy: 0.6982 - val_loss: 0.9680\n",
            "Epoch 5/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m966s\u001b[0m 2s/step - accuracy: 0.8864 - loss: 0.3321 - val_accuracy: 0.6889 - val_loss: 1.0309\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6a943ca8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred_probs_l = LSTM_model.predict(padded_sequences_test)\n",
        "y_pred_lstm = np.argmax(y_pred_probs_l, axis=1)   # predicted class (0–4)\n",
        "y_true_lstm = np.argmax(test_labels, axis=1)"
      ],
      "metadata": {
        "id": "AzglyGeF3wmX",
        "outputId": "f09cb202-1ee8-4226-8b1a-f95c04bc84be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AzglyGeF3wmX",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 242ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(60):\n",
        "    print(f\"Review {i+1}: True={y_true_lstm[i]}, Pred={y_pred_lstm[i]}\")"
      ],
      "metadata": {
        "id": "5dgosFhd5zHv",
        "outputId": "e751b2f5-5a6b-4ad7-d018-32bd06e6ca3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5dgosFhd5zHv",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 1: True=4, Pred=4\n",
            "Review 2: True=4, Pred=4\n",
            "Review 3: True=4, Pred=4\n",
            "Review 4: True=4, Pred=4\n",
            "Review 5: True=4, Pred=4\n",
            "Review 6: True=4, Pred=4\n",
            "Review 7: True=4, Pred=4\n",
            "Review 8: True=4, Pred=4\n",
            "Review 9: True=2, Pred=2\n",
            "Review 10: True=4, Pred=4\n",
            "Review 11: True=4, Pred=4\n",
            "Review 12: True=4, Pred=4\n",
            "Review 13: True=0, Pred=0\n",
            "Review 14: True=1, Pred=1\n",
            "Review 15: True=4, Pred=4\n",
            "Review 16: True=3, Pred=3\n",
            "Review 17: True=0, Pred=1\n",
            "Review 18: True=4, Pred=4\n",
            "Review 19: True=4, Pred=4\n",
            "Review 20: True=1, Pred=1\n",
            "Review 21: True=4, Pred=4\n",
            "Review 22: True=4, Pred=4\n",
            "Review 23: True=4, Pred=4\n",
            "Review 24: True=3, Pred=4\n",
            "Review 25: True=4, Pred=4\n",
            "Review 26: True=4, Pred=4\n",
            "Review 27: True=4, Pred=4\n",
            "Review 28: True=4, Pred=4\n",
            "Review 29: True=4, Pred=4\n",
            "Review 30: True=4, Pred=4\n",
            "Review 31: True=0, Pred=0\n",
            "Review 32: True=4, Pred=2\n",
            "Review 33: True=4, Pred=4\n",
            "Review 34: True=4, Pred=4\n",
            "Review 35: True=3, Pred=3\n",
            "Review 36: True=4, Pred=4\n",
            "Review 37: True=4, Pred=3\n",
            "Review 38: True=4, Pred=4\n",
            "Review 39: True=4, Pred=4\n",
            "Review 40: True=4, Pred=4\n",
            "Review 41: True=4, Pred=1\n",
            "Review 42: True=4, Pred=3\n",
            "Review 43: True=3, Pred=2\n",
            "Review 44: True=4, Pred=4\n",
            "Review 45: True=4, Pred=4\n",
            "Review 46: True=4, Pred=4\n",
            "Review 47: True=3, Pred=2\n",
            "Review 48: True=4, Pred=4\n",
            "Review 49: True=4, Pred=4\n",
            "Review 50: True=1, Pred=1\n",
            "Review 51: True=1, Pred=0\n",
            "Review 52: True=4, Pred=4\n",
            "Review 53: True=2, Pred=4\n",
            "Review 54: True=4, Pred=4\n",
            "Review 55: True=3, Pred=3\n",
            "Review 56: True=4, Pred=4\n",
            "Review 57: True=1, Pred=3\n",
            "Review 58: True=4, Pred=4\n",
            "Review 59: True=0, Pred=0\n",
            "Review 60: True=3, Pred=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(LSTM_model, padded_sequences_train, train_labels, padded_sequences_test, test_labels, train=True)"
      ],
      "metadata": {
        "id": "t3kn0t_05zFy",
        "outputId": "a9bfbbc9-2da6-4eda-a379-1235b5737101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "t3kn0t_05zFy",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 437ms/step\n",
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 93.40%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                     0            1            2            3             4  \\\n",
            "precision     0.936713     0.889610     0.825506     0.905909      0.954573   \n",
            "recall        0.935758     0.735680     0.849583     0.803744      0.988895   \n",
            "f1-score      0.936235     0.805356     0.837372     0.851774      0.971431   \n",
            "support    2942.000000  1676.000000  2400.000000  4540.000000  20442.000000   \n",
            "\n",
            "           accuracy     macro avg  weighted avg  \n",
            "precision  0.934031      0.902462      0.932945  \n",
            "recall     0.934031      0.862732      0.934031  \n",
            "f1-score   0.934031      0.880434      0.932466  \n",
            "support    0.934031  32000.000000  32000.000000  \n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            "[[ 2753    73    31     8    77]\n",
            " [  146  1233   221    23    53]\n",
            " [   15    61  2039   167   118]\n",
            " [    7    11   159  3649   714]\n",
            " [   18     8    20   181 20215]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(LSTM_model, padded_sequences_train, train_labels, padded_sequences_test, test_labels, train=False)"
      ],
      "metadata": {
        "id": "k_FU3MM6CqUH",
        "outputId": "1cf0b14d-87f9-4115-8f3c-398d17b52d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k_FU3MM6CqUH",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 244ms/step\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 68.89%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                    0           1           2            3            4  \\\n",
            "precision    0.590343    0.321070    0.346870     0.382580     0.806330   \n",
            "recall       0.514946    0.229117    0.341667     0.305727     0.877495   \n",
            "f1-score     0.550073    0.267409    0.344249     0.339863     0.840409   \n",
            "support    736.000000  419.000000  600.000000  1135.000000  5110.000000   \n",
            "\n",
            "           accuracy    macro avg  weighted avg  \n",
            "precision  0.688875     0.489438      0.666464  \n",
            "recall     0.688875     0.453790      0.688875  \n",
            "f1-score   0.688875     0.468400      0.675460  \n",
            "support    0.688875  8000.000000   8000.000000  \n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            "[[ 379   86   87   36  148]\n",
            " [  98   96   96   27  102]\n",
            " [  47   55  205  112  181]\n",
            " [  27   23   92  347  646]\n",
            " [  91   39  111  385 4484]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence=['this product is bad and horrible i hate it','Good Quality and very Delight and Great product and recommended']\n",
        "new_sentence=pd.Series(new_sentence)\n",
        "new_sentence=new_sentence.apply(clean_text)\n",
        "new_sentence=new_sentence.apply(remove_punctuation)\n",
        "new_sentence=[stop(t) for t in new_sentence]\n",
        "new_sequences=tokenizer.texts_to_sequences(new_sentence)\n",
        "new_padded_sequences=pad_sequences(new_sequences,maxlen=padded_sequences_train.shape[1])\n",
        "predictions_l=LSTM_model.predict(new_padded_sequences)\n",
        "predicted_classes_lstm = np.argmax(predictions_l, axis=1)\n",
        "print(predicted_classes_lstm)\n"
      ],
      "metadata": {
        "id": "5OmigEYY5zDp",
        "outputId": "7dd72850-0669-4635-bd88-a6298380505b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5OmigEYY5zDp",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "[0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentiment_map = {\n",
        "    0: \"1 Star (Very Negative)\",\n",
        "    1: \"2 Stars (Negative)\",\n",
        "    2: \"3 Stars (Neutral)\",\n",
        "    3: \"4 Stars (Positive)\",\n",
        "    4: \"5 Stars (Very Positive)\"\n",
        "}\n",
        "\n",
        "def predict_sentence(new_sentence, rnn_model, lstm_model, tokenizer, maxlen):\n",
        "    # Convert to Series for preprocessing pipeline\n",
        "    new_sentence = pd.Series(new_sentence)\n",
        "\n",
        "    # Apply your preprocessing steps\n",
        "    new_sentence = new_sentence.apply(clean_text)\n",
        "    new_sentence = new_sentence.apply(remove_punctuation)\n",
        "    new_sentence = [stop(t) for t in new_sentence]  # stopword removal\n",
        "\n",
        "    # Tokenize + pad\n",
        "    new_sequences = tokenizer.texts_to_sequences(new_sentence)\n",
        "    new_padded_sequences = pad_sequences(new_sequences, maxlen=maxlen)\n",
        "\n",
        "    # Predictions\n",
        "    rnn_pred = np.argmax(rnn_model.predict(new_padded_sequences), axis=1)[0]\n",
        "    lstm_pred = np.argmax(lstm_model.predict(new_padded_sequences), axis=1)[0]\n",
        "\n",
        "    # Show results\n",
        "    print(\"Input Review:\", new_sentence[0])\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print(f\"RNN Model Prediction : {sentiment_map[rnn_pred]}\")\n",
        "    print(f\"LSTM Model Prediction: {sentiment_map[lstm_pred]}\")\n"
      ],
      "metadata": {
        "id": "qasHsMmZ8ib2"
      },
      "id": "qasHsMmZ8ib2",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rev=input(\"please enter your review\")\n",
        "predict_sentence(rev, rnn_model, LSTM_model, tokenizer, padded_sequences_train.shape[1])"
      ],
      "metadata": {
        "id": "lWKQCbyxAO-F",
        "outputId": "fabb4946-ca86-416c-ce55-6d7fe2a3413d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lWKQCbyxAO-F",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please enter your reviewWorst experience ever, completely disappointed.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
            "Input Review: worst experience ever completely disappointed\n",
            "----------------------------------------------------\n",
            "RNN Model Prediction : 1 Star (Very Negative)\n",
            "LSTM Model Prediction: 1 Star (Very Negative)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AeNB0c1sSvE_"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}